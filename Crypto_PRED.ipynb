{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce81ca-ebea-4183-9373-808d95e393d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Import Libraries\n",
    "# =============================================================================\n",
    "import re\n",
    "import os\n",
    "import requests                     # For making API calls to CoinMarketCap\n",
    "import pandas as pd                 # For data manipulation and analysis\n",
    "import numpy as np                  # For numerical operations\n",
    "import matplotlib.pyplot as plt     # For plotting graphs\n",
    "import praw\n",
    "import datetime                     # For handling date and time information\n",
    "import nltk                         # For Natural Language Processing\n",
    "import time\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer  # VADER for sentiment analysis\n",
    "from sklearn.linear_model import LinearRegression           # For predictive modeling \n",
    "from sklearn.metrics import mean_absolute_error, r2_score      # For model evaluation\n",
    "\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70213c73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_utc\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mto_datetime([\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-07-07 23:59:53\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     ]\n\u001b[0;32m     17\u001b[0m })\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize zero-shot classification pipeline\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Define candidate labels for relevance\u001b[39;00m\n\u001b[0;32m     23\u001b[0m candidate_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuy signal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msell signal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregulatory news\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data (replace with your actual DataFrame)\n",
    "df = pd.DataFrame({\n",
    "    'created_utc': pd.to_datetime([\n",
    "        \"2025-07-07 23:59:53\",\n",
    "        \"2025-07-07 23:50:14\",\n",
    "        \"2025-07-07 23:30:48\",\n",
    "        \"2025-07-07 22:41:58\",\n",
    "        \"2025-07-07 21:47:55\",\n",
    "    ]),\n",
    "    'text': [\n",
    "        \"What just happened in my account?? Scammed?\",\n",
    "        \"Securing IoMT data with Algorand blockchain, X chain focus\",\n",
    "        \"Has anyone seen these chains/coins before? Iâ€™m curious about ADA performance.\",\n",
    "        \"I paid 6.7 Trillion to ones who got Goxxed\",\n",
    "        \"U.S. government moves Ethereum to Coinbase; Insights and analysis.\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Initialize zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define candidate labels for relevance\n",
    "candidate_labels = [\n",
    "    \"buy signal\", \n",
    "    \"sell signal\", \n",
    "    \"market analysis\",\n",
    "    \"security issue\",\n",
    "    \"technical update\",\n",
    "    \"regulatory news\"\n",
    "]\n",
    "\n",
    "def classify_relevance(text, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Classify a text for relevance to cryptocurrency trading signals/context.\n",
    "    Returns True if any label has score >= threshold.\n",
    "    \"\"\"\n",
    "    result = classifier(text, candidate_labels)\n",
    "    # Check if any label score exceeds the threshold\n",
    "    return any(score >= threshold for score in result['scores'])\n",
    "\n",
    "# Apply classification to DataFrame\n",
    "df['is_relevant'] = df['text'].apply(classify_relevance)\n",
    "\n",
    "# Show filtered results\n",
    "filtered_df = df[df['is_relevant']].copy()\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"AI-Filtered Relevant Posts\", dataframe=filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888d5f00-c6ef-4d35-8253-c1f56e6076f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 29 posts with target flairs.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Function: get_reddit_posts\n",
    "# =============================================================================\n",
    "reddit = praw.Reddit(\n",
    "        client_id=\"EONAlz7JyvxOCdJJ8xpe6A\",\n",
    "        client_secret=\"X-FWW2OvuBV-Pll7OH3c4RNLzYah4Q\",\n",
    "        user_agent=\"crypto-sentiment-bot/0.1 (by /u/BuzzKG)\")\n",
    "\n",
    "def get_reddit_posts_praw(subreddit, limit=200, sleep_between=1.0):\n",
    "    \"\"\"\n",
    "    Fetches the newest posts from a subreddit using PRAW (Reddit's official API).\n",
    "    Respects Reddit rate limits by sleeping between requests.\n",
    "\n",
    "    Parameters:\n",
    "        subreddit (str): Name of the subreddit (e.g., 'cryptocurrency').\n",
    "        limit (int): Number of posts to retrieve.\n",
    "        sleep_between (float): Seconds to sleep between batch fetches.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'created_utc' and 'text' columns.\n",
    "    \"\"\"\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"EONAlz7JyvxOCdJJ8xpe6A\",\n",
    "        client_secret=\"X-FWW2OvuBV-Pll7OH3c4RNLzYah4Q\",\n",
    "        user_agent=\"crypto-sentiment-bot/0.1 (by /u/BuzzKG)\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def fetch_flair_posts(subreddit_name, limit=5000, flairs=None, sleep=0.5):\n",
    "    \"\"\"\n",
    "    Fetch up to `limit` latest posts whose flair is in `flairs`.\n",
    "    Returns a DataFrame with id, created_utc, title, selftext, flair, score, num_comments.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    sub = reddit.subreddit(subreddit_name)\n",
    "    for submission in sub.new(limit=limit):\n",
    "        flair = (submission.link_flair_text or \"\").strip()\n",
    "        if flairs and flair not in flairs:\n",
    "            continue\n",
    "\n",
    "        records.append({\n",
    "            \"id\":           submission.id,\n",
    "            \"created_utc\":  pd.to_datetime(submission.created_utc, unit=\"s\"),\n",
    "            \"flair\":        flair,\n",
    "            \"title\":        submission.title,\n",
    "            \"selftext\":     submission.selftext or \"\",\n",
    "            \"score\":        submission.score,\n",
    "            \"num_comments\": submission.num_comments\n",
    "        })\n",
    "        time.sleep(sleep)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Define the four target flairs (adjust exact text as the sub uses it)\n",
    "TARGET_FLAIRS = {\"MEME\"}\n",
    "\n",
    "df = fetch_flair_posts(\"CryptoCurrency\", limit=3000, flairs=TARGET_FLAIRS)\n",
    "print(f\"Fetched {len(df)} posts with target flairs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72eb5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          id         created_utc flair  \\\n",
      "0   1mphuym 2025-08-13 21:52:50  MEME   \n",
      "1   1mpggdb 2025-08-13 20:58:15  MEME   \n",
      "2   1mpao1m 2025-08-13 17:23:10  MEME   \n",
      "3   1mp90j9 2025-08-13 16:22:41  MEME   \n",
      "4   1moxrn9 2025-08-13 07:19:52  MEME   \n",
      "5   1mofkek 2025-08-12 17:46:03  MEME   \n",
      "6   1mne84g 2025-08-11 14:17:48  MEME   \n",
      "7   1mn8wzg 2025-08-11 10:03:37  MEME   \n",
      "8   1mn1fpx 2025-08-11 02:36:44  MEME   \n",
      "9   1mm1357 2025-08-09 21:40:23  MEME   \n",
      "10  1ml8izs 2025-08-08 22:06:13  MEME   \n",
      "11  1ml66ne 2025-08-08 20:30:29  MEME   \n",
      "12  1mkpyff 2025-08-08 08:44:31  MEME   \n",
      "13  1mkb30j 2025-08-07 20:27:48  MEME   \n",
      "14  1mk0hs9 2025-08-07 13:44:25  MEME   \n",
      "15  1mjbn4t 2025-08-06 17:53:32  MEME   \n",
      "16  1mja1ee 2025-08-06 16:54:03  MEME   \n",
      "17  1mimi7f 2025-08-05 21:49:59  MEME   \n",
      "18  1miclha 2025-08-05 15:39:59  MEME   \n",
      "19  1mi0zi2 2025-08-05 05:42:38  MEME   \n",
      "20  1mgytw8 2025-08-04 00:11:16  MEME   \n",
      "21  1mgbt7v 2025-08-03 05:59:51  MEME   \n",
      "22  1mg38zv 2025-08-02 22:33:03  MEME   \n",
      "23  1mfw1it 2025-08-02 17:21:55  MEME   \n",
      "24  1mezjen 2025-08-01 15:29:25  MEME   \n",
      "25  1me4pf3 2025-07-31 15:31:17  MEME   \n",
      "26  1me2wl4 2025-07-31 14:21:39  MEME   \n",
      "27  1mdmwux 2025-07-31 00:11:21  MEME   \n",
      "28  1mcygkn 2025-07-30 05:40:34  MEME   \n",
      "\n",
      "                                                title  \\\n",
      "0                       Ethereum vs. Ethereum Killers   \n",
      "1                           I Like Men Who Take Risks   \n",
      "2   In my defense ETH is still down 50% against Bi...   \n",
      "3                          Courtesy of u/boldleonidas   \n",
      "4            From Suits to Smackdowns - ETH Q3 Energy   \n",
      "5                                How to Speedrun PTSD   \n",
      "6                   What if I hold a little longer...   \n",
      "7                        BTC Breaks $121k, We're Back   \n",
      "8                                    ATH Celebrations   \n",
      "9                        You Know What Is Coming Next   \n",
      "10                       ETH Last Week: ETH This Week   \n",
      "11                                Me Wanting To Flirt   \n",
      "12        Those buttons are $4000 Ethereum Resistance   \n",
      "13                           Men only want one thing:   \n",
      "14                                 My cute Dogecoins!   \n",
      "15                           China Bans Bitcoin (BTC)   \n",
      "16          Skip the blood tests -Just check the eyes   \n",
      "17  I will never tell when I make it big from meme...   \n",
      "18                  everyone: just bought the dip me:   \n",
      "19                          The Eternal Cycle of FOMO   \n",
      "20  Remember when Solana released this ad and then...   \n",
      "21  I Have Moved On To Other Things - Satoshi Naka...   \n",
      "22                             Crypto Mathematics 101   \n",
      "23  Is another case of down first and then I told you   \n",
      "24      Sometimes 'To the moon' need to take a U-Turn   \n",
      "25  Ethereum (ETH) Holders Watching $3900 Hit Agai...   \n",
      "26                                 From Lame to Flame   \n",
      "27                              Watch Out Crypto Bros   \n",
      "28                                    There Is No Top   \n",
      "\n",
      "                                             selftext  score  num_comments  \n",
      "0                                                        210            46  \n",
      "1   Source: [https://x.com/naiivememe/status/19556...    956            60  \n",
      "2                                                        207            60  \n",
      "3                                                        594            31  \n",
      "4                                                        472            35  \n",
      "5   Source: [https://x.com/naiivememe/status/19553...   1059            92  \n",
      "6                                                       2363            91  \n",
      "7   Source: [https://x.com/naiivememe/status/19545...    496            38  \n",
      "8                                                       1685            45  \n",
      "9                                                       1155            68  \n",
      "10                                                      1284            48  \n",
      "11                                                       341            19  \n",
      "12                                                      3068           122  \n",
      "13  Source: [https://x.com/naiivememe/status/19531...    982            44  \n",
      "14                                                         0             1  \n",
      "15  Source: [https://x.com/LilMoonLambo/status/195...    776            43  \n",
      "16                                                      3979            74  \n",
      "17                                                       209            22  \n",
      "18                                                      1280            78  \n",
      "19                                                         0             2  \n",
      "20                                                       165            34  \n",
      "21                                                       477            69  \n",
      "22                                                      1389            22  \n",
      "23                                                      1265           272  \n",
      "24                                                      1166            61  \n",
      "25                                                       958            54  \n",
      "26                                                      4125           108  \n",
      "27                                                      1301            24  \n",
      "28                                                       144            53  >\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866a17dc-90d2-4af1-ba93-6329319cd203",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reddit_cryptocurrency_posts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load Reddit Data from Kaggle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Read the CSV file containing Reddit posts. The file should include columns like:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 'created_utc', 'title', and 'selftext'.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m reddit_kaggle_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreddit_cryptocurrency_posts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# If there is no 'text' column, combine 'title' and 'selftext' to form a complete post text.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m reddit_kaggle_df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\DBABA\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\DBABA\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\DBABA\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\DBABA\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\DBABA\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reddit_cryptocurrency_posts.csv'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load Reddit Data from Kaggle\n",
    "# =============================================================================\n",
    "# Read the CSV file containing Reddit posts. The file should include columns like:\n",
    "# 'created_utc', 'title', and 'selftext'.\n",
    "reddit_kaggle_df = pd.read_csv('reddit_cryptocurrency_posts.csv')\n",
    "\n",
    "# If there is no 'text' column, combine 'title' and 'selftext' to form a complete post text.\n",
    "if 'text' not in reddit_kaggle_df.columns:\n",
    "    reddit_kaggle_df['text'] = reddit_kaggle_df['title'].fillna('') + \" \" + reddit_kaggle_df['selftext'].fillna('')\n",
    "\n",
    "# Convert the 'created_utc' column to datetime.\n",
    "# If the values are UNIX epoch seconds, specify unit='s'; otherwise, let pandas infer the format.\n",
    "if reddit_kaggle_df['created_utc'].dtype in [int, float]:\n",
    "    reddit_kaggle_df['created_utc'] = pd.to_datetime(reddit_kaggle_df['created_utc'], unit='s')\n",
    "else:\n",
    "    reddit_kaggle_df['created_utc'] = pd.to_datetime(reddit_kaggle_df['created_utc'])\n",
    "\n",
    "print(\"Loaded Reddit Data from Kaggle:\")\n",
    "print(reddit_kaggle_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8232e2-e84f-41bf-9082-0e59275ce83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
